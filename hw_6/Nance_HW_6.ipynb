{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Download the zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Write a set of methods that takes as input one of these images, and then computes real-numbered features as the return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.linalg import norm\n",
    "from scipy import sum, average\n",
    "\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.draw import ellipse\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh, daisy\n",
    "from skimage.filters import gaussian_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from skimage import feature\n",
    "from skimage.feature import shape_index\n",
    "from scipy.misc import imsave\n",
    "from scipy.signal import fftconvolve, find_peaks_cwt\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from skimage import measure\n",
    "\n",
    "from imutils import contours\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features we'll use:\n",
    "\n",
    "1. Correlation coefficient of R and G channels\n",
    "2. Correlation coefficient of G and B channels\n",
    "3. Correlation coefficient of B and R channels\n",
    "4. Average of R channel colors\n",
    "5. Average of B channel colors\n",
    "6. Average of G channel colors\n",
    "7. Variance of R color channel\n",
    "8. Variance of B color channel\n",
    "9. Variance of G color channel\n",
    "10. Corner detection length\n",
    "11. Corner detection ratio\n",
    "12. Length of blobs\n",
    "13. Number of blobs\n",
    "14. Number of contours\n",
    "15. Measure of curvature using spherical caps\n",
    "16. Image array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_coeff(image):\n",
    "    '''\n",
    "    Calculate the correlation coefficient between each color channel.\n",
    "    '''\n",
    "    axis1 = len(image)\n",
    "    axis2 = len(image[0])\n",
    "    if len(image.shape) > 2:\n",
    "        # Reshape and transpose the image to extract color channels\n",
    "        colors = np.reshape(image, (axis1*axis2, 3)).T\n",
    "        reds = colors[0]\n",
    "        greens = colors[1]\n",
    "        blues = colors[2]\n",
    "        RG_cc = np.corrcoef(reds, greens)\n",
    "        GB_cc = np.corrcoef(greens, blues)\n",
    "        BR_cc = np.corrcoef(blues, reds)\n",
    "        return RG_cc[0,1], GB_cc[0,1], BR_cc[0,1]\n",
    "    else:\n",
    "        return 0, 0, 0\n",
    "\n",
    "def average_color(image):\n",
    "    '''\n",
    "    Find average color per row\n",
    "    '''\n",
    "    axis1 = len(image)\n",
    "    axis2 = len(image[0])\n",
    "    if len(image.shape) > 2:\n",
    "        # Reshape and transpose the image to extract color channels\n",
    "        colors = np.reshape(image, (axis1*axis2, 3)).T\n",
    "        reds = colors[0]\n",
    "        greens = colors[1]\n",
    "        blues = colors[2]\n",
    "        R_avg = np.average(reds)\n",
    "        G_avg = np.average(greens)\n",
    "        B_avg = np.average(blues)\n",
    "        return R_avg, G_avg, B_avg\n",
    "    else:\n",
    "        return 0, 0, 0\n",
    "    return average_color\n",
    "\n",
    "def color_channel_variance(image):\n",
    "    \"\"\"\n",
    "    Calculate the variance of each color channel.\n",
    "    \"\"\"\n",
    "    axis1 = len(image)\n",
    "    axis2 = len(image[0])\n",
    "    if len(image.shape) > 2:\n",
    "        colors = np.reshape(image, (axis1*axis2,3)).T\n",
    "        reds = colors[0]\n",
    "        greens = colors[1]\n",
    "        blues = colors[2]\n",
    "        # find each average\n",
    "        R_var = np.var(reds)\n",
    "        G_var = np.var(greens)\n",
    "        B_var = np.var(blues)\n",
    "        return R_var, G_var, B_var \n",
    "    else:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "def corner_detection(image):\n",
    "    '''\n",
    "    Detects corner points using the Harris corner detector and determines the \n",
    "    subpixel position of corners\n",
    "    '''\n",
    "    # Convert image to greyscale\n",
    "    image_gray = rgb2gray(image)\n",
    "    \n",
    "    # find the corners using Harris corner detector\n",
    "    coords = corner_peaks(corner_harris(image_gray), min_distance=5)\n",
    "    coords_subpix = corner_subpix(image_gray, coords, window_size=13)\n",
    "    \n",
    "    # find ratio of the maximum vertical distance and maximum horizontal distance between corners \n",
    "    if len(coords) > 1:\n",
    "        max_vertical = max(coords.T[0])\n",
    "        min_vertical = min(coords.T[0])\n",
    "        max_horizontal = max(coords.T[1])\n",
    "        min_horizontal = min(coords.T[1])\n",
    "        ratio = (max_vertical - min_vertical)/(max_horizontal - min_horizontal)\n",
    "        if ratio == np.inf:\n",
    "            return 0, 0\n",
    "        else:\n",
    "            return len(coords), ratio\n",
    "    elif len(coords) == 1:\n",
    "        return 1, 1\n",
    "    elif len(coords) == 0:\n",
    "        return 0, 0\n",
    "\n",
    "def blob_size(image):\n",
    "    '''\n",
    "    Calculate the average size of blobs\n",
    "    '''\n",
    "    # Convert image to greyscale\n",
    "    image_gray = rgb2gray(image)\n",
    "    \n",
    "    # Finds blobs in the given grayscale image using Determinant of Hessian method.\n",
    "    # This is the fastest approach to finding blobs; best for large blobs\n",
    "    blobs_doh = blob_doh(image_gray, max_sigma=30, threshold=.01)\n",
    "    \n",
    "    # Calculate average size of blobs\n",
    "    if len(blobs_doh) > 0:\n",
    "        blob_sizes = blobs_doh.T[2]\n",
    "        avg_size = np.mean(blob_sizes)\n",
    "        return len(blobs_doh), avg_size\n",
    "    elif len(blobs_doh) == 0:\n",
    "        return 0, 0\n",
    "\n",
    "def contours(image):\n",
    "    '''\n",
    "    Find and extract contours on images. \n",
    "    Then calculate the number of contours. \n",
    "    '''\n",
    "    image_gray = rgb2gray(image) # Convert to binary images for better accuracy\n",
    "    \n",
    "    # Find contours at a constant value of 0.8\n",
    "    contours = measure.find_contours(image_gray, 0.8)\n",
    "    \n",
    "    return len(contours)\n",
    "\n",
    "def shape_cap_index(image):\n",
    "    '''\n",
    "    The shape index is a single valued measure of local curvature. \n",
    "    A shape index of 1 represents ‘spherical caps’, the shape of the spots we \n",
    "    want to detect.\n",
    "    '''\n",
    "    # Convert image to greyscale\n",
    "    image_gray = rgb2gray(image)\n",
    "    \n",
    "    # We want to detect 'spherical caps', so we threshold the shape index map to\n",
    "    # find points which are 'spherical caps' (~1)\n",
    "    target = 1\n",
    "    delta = 0.05\n",
    "    s = shape_index(image_gray)\n",
    "    \n",
    "    point_y, point_x = np.where(np.abs(s - target) < delta)\n",
    "    point_z = image[point_y, point_x]\n",
    "    \n",
    "    # The shape index map produces the shape, even that of noise.\n",
    "    # In order to reduce the impact of noise, we apply a Gaussian filter to it,\n",
    "    # and show the results once in\n",
    "    \n",
    "    s_smooth = ndi.gaussian_filter(s, sigma=0.5)\n",
    "\n",
    "    point_y_s, point_x_s = np.where(np.abs(s_smooth - target) < delta)\n",
    "    point_z_s = image[point_y_s, point_x_s]\n",
    "    \n",
    "    return len(point_z_s)\n",
    "\n",
    "\n",
    "def image_array_size(image):\n",
    "    '''\n",
    "    Find the image array size and total number of pixels\n",
    "    '''\n",
    "    # Find number of pixels in each axis\n",
    "    x_axis = len(image)\n",
    "    y_axis = len(image[0])\n",
    "    \n",
    "    # Calculate total number of pixels\n",
    "    total = x_axis * y_axis\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/skimage/feature/corner.py:373: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (2.0 / np.pi) * np.arctan((l2 + l1) / (l2 - l1))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/ipykernel_launcher.py:133: RuntimeWarning: invalid value encountered in less\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/ipykernel_launcher.py:142: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235626767200754 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/skimage/feature/corner.py:373: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (2.0 / np.pi) * np.arctan((l2 + l1) / (l2 - l1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471253534401508 %\n",
      "0.706880301602262 %\n",
      "0.942507068803016 %\n",
      "1.17813383600377 %\n",
      "1.413760603204524 %\n",
      "1.649387370405278 %\n",
      "1.885014137606032 %\n",
      "2.1206409048067862 %\n",
      "2.35626767200754 %\n",
      "2.591894439208294 %\n",
      "2.827521206409048 %\n",
      "3.063147973609802 %\n",
      "3.298774740810556 %\n",
      "3.5344015080113103 %\n",
      "3.770028275212064 %\n",
      "4.005655042412818 %\n",
      "4.2412818096135725 %\n",
      "4.476908576814326 %\n",
      "4.71253534401508 %\n",
      "4.948162111215834 %\n",
      "5.183788878416588 %\n",
      "5.419415645617343 %\n",
      "5.655042412818096 %\n",
      "5.89066918001885 %\n",
      "6.126295947219604 %\n",
      "6.361922714420358 %\n",
      "6.597549481621112 %\n",
      "6.833176248821866 %\n",
      "7.0688030160226205 %\n",
      "7.304429783223374 %\n",
      "7.540056550424128 %\n",
      "7.775683317624882 %\n",
      "8.011310084825636 %\n",
      "8.24693685202639 %\n",
      "8.482563619227145 %\n",
      "8.718190386427898 %\n",
      "8.953817153628652 %\n",
      "9.189443920829406 %\n",
      "9.42507068803016 %\n",
      "9.660697455230915 %\n",
      "9.896324222431668 %\n",
      "10.131950989632422 %\n",
      "10.367577756833176 %\n",
      "10.60320452403393 %\n",
      "10.838831291234685 %\n",
      "11.074458058435438 %\n",
      "11.310084825636192 %\n",
      "11.545711592836946 %\n",
      "11.7813383600377 %\n",
      "12.016965127238453 %\n",
      "12.252591894439208 %\n",
      "12.488218661639962 %\n",
      "12.723845428840717 %\n",
      "12.959472196041471 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/ipykernel_launcher.py:77: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.195098963242224 %\n",
      "13.430725730442978 %\n",
      "13.666352497643732 %\n",
      "13.901979264844487 %\n",
      "14.137606032045241 %\n",
      "14.373232799245994 %\n",
      "14.608859566446748 %\n",
      "14.844486333647502 %\n",
      "15.080113100848257 %\n",
      "15.315739868049011 %\n",
      "15.551366635249764 %\n",
      "15.786993402450518 %\n",
      "16.022620169651272 %\n",
      "16.258246936852025 %\n",
      "16.49387370405278 %\n",
      "16.729500471253534 %\n",
      "16.96512723845429 %\n",
      "17.200754005655043 %\n",
      "17.436380772855795 %\n",
      "17.67200754005655 %\n",
      "17.907634307257304 %\n",
      "18.14326107445806 %\n",
      "18.378887841658813 %\n",
      "18.614514608859565 %\n",
      "18.85014137606032 %\n",
      "19.085768143261074 %\n",
      "19.32139491046183 %\n",
      "19.557021677662583 %\n",
      "19.792648444863335 %\n",
      "20.02827521206409 %\n",
      "20.263901979264844 %\n",
      "20.4995287464656 %\n",
      "20.735155513666353 %\n",
      "20.970782280867105 %\n",
      "21.20640904806786 %\n",
      "21.442035815268614 %\n",
      "21.67766258246937 %\n",
      "21.913289349670123 %\n",
      "22.148916116870875 %\n",
      "22.38454288407163 %\n",
      "22.620169651272384 %\n",
      "22.855796418473137 %\n",
      "23.091423185673893 %\n",
      "23.327049952874646 %\n",
      "23.5626767200754 %\n",
      "23.798303487276154 %\n",
      "24.033930254476907 %\n",
      "24.269557021677663 %\n",
      "24.505183788878416 %\n",
      "24.740810556079172 %\n",
      "24.976437323279924 %\n",
      "25.212064090480677 %\n",
      "25.447690857681433 %\n",
      "25.683317624882186 %\n",
      "25.918944392082942 %\n",
      "26.154571159283694 %\n",
      "26.390197926484447 %\n",
      "26.625824693685203 %\n",
      "26.861451460885956 %\n",
      "27.097078228086712 %\n",
      "27.332704995287465 %\n",
      "27.568331762488217 %\n",
      "27.803958529688973 %\n",
      "28.039585296889726 %\n",
      "28.275212064090482 %\n",
      "28.510838831291235 %\n",
      "28.746465598491987 %\n",
      "28.982092365692743 %\n",
      "29.217719132893496 %\n",
      "29.453345900094252 %\n",
      "29.688972667295005 %\n",
      "29.924599434495757 %\n",
      "30.160226201696513 %\n",
      "30.395852968897266 %\n",
      "30.631479736098022 %\n",
      "30.867106503298775 %\n",
      "31.102733270499527 %\n",
      "31.338360037700284 %\n",
      "31.573986804901036 %\n",
      "31.809613572101792 %\n",
      "32.045240339302545 %\n",
      "32.2808671065033 %\n",
      "32.51649387370405 %\n",
      "32.752120640904806 %\n",
      "32.98774740810556 %\n",
      "33.22337417530631 %\n",
      "33.45900094250707 %\n",
      "33.694627709707824 %\n",
      "33.93025447690858 %\n",
      "34.16588124410933 %\n",
      "34.401508011310085 %\n",
      "34.63713477851084 %\n",
      "34.87276154571159 %\n",
      "35.108388312912346 %\n",
      "35.3440150801131 %\n",
      "35.57964184731385 %\n",
      "35.81526861451461 %\n",
      "36.050895381715364 %\n",
      "36.28652214891612 %\n",
      "36.52214891611687 %\n",
      "36.757775683317625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 15138816 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 15663104 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 13107200 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3368026112 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18939904 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19464192 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19988480 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20512768 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21037056 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21561344 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22085632 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 327680 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1572864 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22609920 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.99340245051838 %\n",
      "37.22902921771913 %\n",
      "37.46465598491989 %\n",
      "37.70028275212064 %\n",
      "37.93590951932139 %\n",
      "38.17153628652215 %\n",
      "38.407163053722904 %\n",
      "38.64278982092366 %\n",
      "38.87841658812441 %\n",
      "39.114043355325165 %\n",
      "39.34967012252592 %\n",
      "39.58529688972667 %\n",
      "39.82092365692743 %\n",
      "40.05655042412818 %\n",
      "40.29217719132893 %\n",
      "40.52780395852969 %\n",
      "40.763430725730444 %\n",
      "40.9990574929312 %\n",
      "41.23468426013195 %\n",
      "41.470311027332706 %\n",
      "41.70593779453346 %\n",
      "41.94156456173421 %\n",
      "42.17719132893497 %\n",
      "42.41281809613572 %\n",
      "42.64844486333647 %\n",
      "42.88407163053723 %\n",
      "43.119698397737984 %\n",
      "43.35532516493874 %\n",
      "43.59095193213949 %\n",
      "43.826578699340246 %\n",
      "44.062205466541 %\n",
      "44.29783223374175 %\n",
      "44.53345900094251 %\n",
      "44.76908576814326 %\n",
      "45.00471253534401 %\n",
      "45.24033930254477 %\n",
      "45.475966069745525 %\n",
      "45.711592836946274 %\n",
      "45.94721960414703 %\n",
      "46.182846371347786 %\n",
      "46.41847313854854 %\n",
      "46.65409990574929 %\n",
      "46.88972667295005 %\n",
      "47.1253534401508 %\n",
      "47.36098020735155 %\n",
      "47.59660697455231 %\n",
      "47.832233741753065 %\n",
      "48.067860508953814 %\n",
      "48.30348727615457 %\n",
      "48.539114043355326 %\n",
      "48.77474081055608 %\n",
      "49.01036757775683 %\n",
      "49.24599434495759 %\n",
      "49.481621112158344 %\n",
      "49.71724787935909 %\n",
      "49.95287464655985 %\n",
      "50.188501413760605 %\n",
      "50.424128180961354 %\n",
      "50.65975494816211 %\n",
      "50.895381715362866 %\n",
      "51.13100848256362 %\n",
      "51.36663524976437 %\n",
      "51.60226201696513 %\n",
      "51.837888784165884 %\n",
      "52.07351555136663 %\n",
      "52.30914231856739 %\n",
      "52.544769085768145 %\n",
      "52.780395852968894 %\n",
      "53.01602262016965 %\n",
      "53.251649387370406 %\n",
      "53.48727615457116 %\n",
      "53.72290292177191 %\n",
      "53.95852968897267 %\n",
      "54.194156456173424 %\n",
      "54.42978322337417 %\n",
      "54.66540999057493 %\n",
      "54.901036757775685 %\n",
      "55.136663524976434 %\n",
      "55.37229029217719 %\n",
      "55.60791705937795 %\n",
      "55.8435438265787 %\n",
      "56.07917059377945 %\n",
      "56.31479736098021 %\n",
      "56.550424128180964 %\n",
      "56.78605089538171 %\n",
      "57.02167766258247 %\n",
      "57.257304429783225 %\n",
      "57.492931196983974 %\n",
      "57.72855796418473 %\n",
      "57.96418473138549 %\n",
      "58.19981149858624 %\n",
      "58.43543826578699 %\n",
      "58.67106503298775 %\n",
      "58.906691800188504 %\n",
      "59.14231856738925 %\n",
      "59.37794533459001 %\n",
      "59.613572101790766 %\n",
      "59.849198868991515 %\n",
      "60.08482563619227 %\n",
      "60.32045240339303 %\n",
      "60.556079170593776 %\n",
      "60.79170593779453 %\n",
      "61.02733270499529 %\n",
      "61.262959472196044 %\n",
      "61.49858623939679 %\n",
      "61.73421300659755 %\n",
      "61.969839773798306 %\n",
      "62.205466540999055 %\n",
      "62.44109330819981 %\n",
      "62.67672007540057 %\n",
      "62.912346842601316 %\n",
      "63.14797360980207 %\n",
      "63.38360037700283 %\n",
      "63.619227144203585 %\n",
      "63.854853911404334 %\n",
      "64.09048067860509 %\n",
      "64.32610744580585 %\n",
      "64.5617342130066 %\n",
      "64.79736098020736 %\n",
      "65.0329877474081 %\n",
      "65.26861451460886 %\n",
      "65.50424128180961 %\n",
      "65.73986804901037 %\n",
      "65.97549481621112 %\n",
      "66.21112158341188 %\n",
      "66.44674835061262 %\n",
      "66.68237511781338 %\n",
      "66.91800188501414 %\n",
      "67.15362865221489 %\n",
      "67.38925541941565 %\n",
      "67.6248821866164 %\n",
      "67.86050895381716 %\n",
      "68.0961357210179 %\n",
      "68.33176248821866 %\n",
      "68.56738925541941 %\n",
      "68.80301602262017 %\n",
      "69.03864278982093 %\n",
      "69.27426955702168 %\n",
      "69.50989632422244 %\n",
      "69.74552309142318 %\n",
      "69.98114985862394 %\n",
      "70.21677662582469 %\n",
      "70.45240339302545 %\n",
      "70.6880301602262 %\n",
      "70.92365692742696 %\n",
      "71.1592836946277 %\n",
      "71.39491046182846 %\n",
      "71.63053722902922 %\n",
      "71.86616399622997 %\n",
      "72.10179076343073 %\n",
      "72.33741753063148 %\n",
      "72.57304429783224 %\n",
      "72.80867106503298 %\n",
      "73.04429783223374 %\n",
      "73.2799245994345 %\n",
      "73.51555136663525 %\n",
      "73.751178133836 %\n",
      "73.98680490103676 %\n",
      "74.2224316682375 %\n",
      "74.45805843543826 %\n",
      "74.69368520263902 %\n",
      "74.92931196983977 %\n",
      "75.16493873704053 %\n",
      "75.40056550424129 %\n",
      "75.63619227144204 %\n",
      "75.87181903864278 %\n",
      "76.10744580584354 %\n",
      "76.3430725730443 %\n",
      "76.57869934024505 %\n",
      "76.81432610744581 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6553600 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 83886080 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 62914560 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 23134208 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 23658496 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 24182784 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 520290304 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 184614912 bytes but only got 898. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.04995287464656 %\n",
      "77.28557964184732 %\n",
      "77.52120640904806 %\n",
      "77.75683317624882 %\n",
      "77.99245994344957 %\n",
      "78.22808671065033 %\n",
      "78.46371347785109 %\n",
      "78.69934024505184 %\n",
      "78.93496701225259 %\n",
      "79.17059377945334 %\n",
      "79.4062205466541 %\n",
      "79.64184731385485 %\n",
      "79.87747408105561 %\n",
      "80.11310084825637 %\n",
      "80.34872761545712 %\n",
      "80.58435438265786 %\n",
      "80.81998114985862 %\n",
      "81.05560791705938 %\n",
      "81.29123468426013 %\n",
      "81.52686145146089 %\n",
      "81.76248821866164 %\n",
      "81.9981149858624 %\n",
      "82.23374175306314 %\n",
      "82.4693685202639 %\n",
      "82.70499528746466 %\n",
      "82.94062205466541 %\n",
      "83.17624882186617 %\n",
      "83.41187558906692 %\n",
      "83.64750235626767 %\n",
      "83.88312912346842 %\n",
      "84.11875589066918 %\n",
      "84.35438265786993 %\n",
      "84.59000942507069 %\n",
      "84.82563619227145 %\n",
      "85.0612629594722 %\n",
      "85.29688972667294 %\n",
      "85.5325164938737 %\n",
      "85.76814326107446 %\n",
      "86.00377002827521 %\n",
      "86.23939679547597 %\n",
      "86.47502356267672 %\n",
      "86.71065032987748 %\n",
      "86.94627709707822 %\n",
      "87.18190386427898 %\n",
      "87.41753063147974 %\n",
      "87.65315739868049 %\n",
      "87.88878416588125 %\n",
      "88.124410933082 %\n",
      "88.36003770028275 %\n",
      "88.5956644674835 %\n",
      "88.83129123468426 %\n",
      "89.06691800188501 %\n",
      "89.30254476908577 %\n",
      "89.53817153628653 %\n",
      "89.77379830348728 %\n",
      "90.00942507068802 %\n",
      "90.24505183788878 %\n",
      "90.48067860508954 %\n",
      "90.7163053722903 %\n",
      "90.95193213949105 %\n",
      "91.1875589066918 %\n",
      "91.42318567389255 %\n",
      "91.6588124410933 %\n",
      "91.89443920829406 %\n",
      "92.13006597549482 %\n",
      "92.36569274269557 %\n",
      "92.60131950989633 %\n",
      "92.83694627709708 %\n",
      "93.07257304429783 %\n",
      "93.30819981149858 %\n",
      "93.54382657869934 %\n",
      "93.7794533459001 %\n",
      "94.01508011310085 %\n",
      "94.2507068803016 %\n",
      "94.48633364750236 %\n",
      "94.7219604147031 %\n",
      "94.95758718190386 %\n",
      "95.19321394910462 %\n",
      "95.42884071630537 %\n",
      "95.66446748350613 %\n",
      "95.90009425070689 %\n",
      "96.13572101790763 %\n",
      "96.37134778510838 %\n",
      "96.60697455230914 %\n",
      "96.8426013195099 %\n",
      "97.07822808671065 %\n",
      "97.31385485391141 %\n",
      "97.54948162111216 %\n",
      "97.7851083883129 %\n",
      "98.02073515551366 %\n",
      "98.25636192271442 %\n",
      "98.49198868991517 %\n",
      "98.72761545711593 %\n",
      "98.96324222431669 %\n",
      "99.19886899151744 %\n",
      "99.43449575871819 %\n",
      "99.67012252591894 %\n",
      "99.9057492931197 %\n"
     ]
    }
   ],
   "source": [
    "# An array of zeroes with dimensions of the number of images and the number of feature\n",
    "# extractors, respectively\n",
    "X = np.zeros((4244,16))\n",
    "\n",
    "# An empty list that we will populate with our classifications\n",
    "Y = []\n",
    "\n",
    "counter = 0\n",
    "ticker = 0\n",
    "index = 0\n",
    "for folder in os.listdir(\"50_categories/\"):\n",
    "    if folder != \".DS_Store\":\n",
    "        for file in os.listdir(\"50_categories/\"+str(folder)):\n",
    "            # add classification to Y\n",
    "            Y.append(str(folder))\n",
    "            # get image\n",
    "            head,tail = os.path.split(file)\n",
    "            path = \"50_categories/\"+str(folder)+\"/\"+tail\n",
    "            image = imread(path) \n",
    "            # obtain features\n",
    "            feature1, feature2, feature3 = correlation_coeff(image)\n",
    "            feature4, feature5, feature6 = average_color(image)\n",
    "            feature7, feature8, feature9 = color_channel_variance(image)\n",
    "            feature10, feature11 = corner_detection(image)\n",
    "            #feature11 = blob_position_detector(image)\n",
    "            feature12, feature13 = blob_size(image)\n",
    "            feature14 = contours(image)\n",
    "            feature15 = shape_cap_index(image)\n",
    "            feature16 = image_array_size(image)\n",
    "            # add features to X\n",
    "            X[index][0] = feature1\n",
    "            X[index][1] = feature2\n",
    "            X[index][2] = feature3\n",
    "            X[index][3] = feature4\n",
    "            X[index][4] = feature5\n",
    "            X[index][5] = feature6\n",
    "            X[index][6] = feature7\n",
    "            X[index][7] = feature8\n",
    "            X[index][8] = feature9\n",
    "            X[index][9] = feature10\n",
    "            X[index][10] = feature11\n",
    "            X[index][11] = feature12\n",
    "            X[index][12] = feature13\n",
    "            X[index][13] = feature14\n",
    "            X[index][14] = feature15\n",
    "            X[index][15] = feature16\n",
    "            index+=1\n",
    "            # print progress\n",
    "            counter+=1\n",
    "            ticker+=1\n",
    "            if ticker == 10:\n",
    "                ticker = 0\n",
    "                print(100*index/4244, \"%\")\n",
    "                \n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gorilla' 'gorilla' 'gorilla' 'gorilla' 'gorilla']\n",
      "[[  9.77235699e-01   9.75400072e-01   9.34378916e-01   1.49408592e+02\n",
      "    1.48160234e+02   1.40587114e+02   5.79529736e+03   6.34444895e+03\n",
      "    6.03614109e+03   4.20000000e+01   6.25827815e-01   3.60000000e+01\n",
      "    1.19197531e+01   1.53000000e+02   0.00000000e+00   1.11331000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.88975044e-01   9.93627882e-01   9.74595498e-01   6.19314538e+01\n",
      "    6.81960504e+01   7.28912773e+01   1.67321734e+03   1.69043980e+03\n",
      "    1.83256736e+03   4.00000000e+00   4.01315789e+00   8.00000000e+00\n",
      "    5.83333333e+00   9.40000000e+01   1.00000000e+00   1.19000000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.73526804e-01   9.67097528e-01   9.66893784e-01   7.58049625e+01\n",
      "    9.42212500e+01   8.40715250e+01   3.61508836e+03   3.56010937e+03\n",
      "    3.48639676e+03   8.20000000e+01   1.43799472e+00   3.50000000e+01\n",
      "    5.97142857e+00   5.40000000e+02   6.00000000e+00   2.40000000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.87984505e-01   8.25380123e-01   7.79838852e-01   7.16098277e+01\n",
      "    7.41308441e+01   6.40486577e+01   3.47780874e+03   3.12808730e+03\n",
      "    1.00766105e+03   4.00000000e+01   2.09809264e-01   1.00000000e+00\n",
      "    3.00000000e+01   4.20000000e+01   4.00000000e+00   3.93216000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.87575055e-01   9.48646741e-01   9.66887032e-01   5.48886301e+01\n",
      "    5.67121005e+01   4.70969680e+01   3.55029232e+03   3.64301773e+03\n",
      "    2.43026090e+03   5.30000000e+01   1.22463768e+00   7.00000000e+00\n",
      "    1.80317460e+01   4.04000000e+02   0.00000000e+00   1.09500000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "['iguana' 'ostrich' 'speed-boat' 'snake' 'starfish']\n",
      "[[  9.68370582e-01   9.89231157e-01   9.47909703e-01   6.71784706e+01\n",
      "    5.60657923e+01   5.32663466e+01   5.49948125e+03   4.51689235e+03\n",
      "    4.51656417e+03   1.01000000e+02   6.87969925e-01   4.10000000e+01\n",
      "    6.42276423e+00   3.09000000e+02   1.00000000e+00   5.66480000e+04\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.45013164e-01   9.40605435e-01   9.19202018e-01   8.40515507e+01\n",
      "    1.12689935e+02   1.06275824e+02   1.78795665e+03   1.55007618e+03\n",
      "    1.40968505e+03   7.50000000e+01   7.52895753e-01   7.00000000e+00\n",
      "    4.22222222e+00   3.44000000e+02   0.00000000e+00   8.67690000e+04\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  7.34330939e-01   8.87387516e-01   3.98175399e-01   1.15781114e+02\n",
      "    1.36344148e+02   1.58208109e+02   3.95075882e+03   2.29478719e+03\n",
      "    2.64238137e+03   2.60000000e+01   3.66666667e-01   1.70000000e+01\n",
      "    1.12352941e+01   2.09000000e+02   0.00000000e+00   1.06800000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.77895614e-01   9.75153105e-01   9.70244680e-01   1.36836064e+02\n",
      "    1.37838672e+02   1.30974331e+02   1.02588124e+03   1.13294916e+03\n",
      "    1.43506959e+03   6.50000000e+01   7.58241758e-01   1.00000000e+00\n",
      "    4.22222222e+00   1.81000000e+02   0.00000000e+00   1.87500000e+05\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.21985794e-01   9.91297565e-01   9.43864489e-01   3.74597753e+01\n",
      "    5.13000250e+01   4.88655556e+01   3.35133967e+03   4.48001381e+03\n",
      "    4.00637917e+03   1.05000000e+02   9.28571429e-01   1.20000000e+01\n",
      "    1.22777778e+01   1.82000000e+02   0.00000000e+00   8.01000000e+04\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "[  9.68370582e-01   9.89231157e-01   9.47909703e-01 ...,   4.22222222e+00\n",
      "   3.54000000e+02   6.09000000e+04]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Shuffle the data \n",
    "'''\n",
    "\n",
    "import random\n",
    "\n",
    "print(Y[:5])\n",
    "print(X[:5])\n",
    "\n",
    "combined = list(zip(X, Y))\n",
    "random.shuffle(combined)\n",
    "\n",
    "X[:], Y[:] = zip(*combined)\n",
    "\n",
    "print(Y[:5])\n",
    "print(X[:5])\n",
    "print(X[X!=0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 3819\n",
      "testing size: 425\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Separate the data into training data and testing data.\n",
    "We will use 90% of the data as training data\n",
    "'''\n",
    "\n",
    "train = int(len(Y)*0.9)\n",
    "X_train = X[:train]\n",
    "Y_train = Y[:train]\n",
    "print(\"training size: \" + str(len(Y_train)))\n",
    "# testing set\n",
    "X_test = X[train:]\n",
    "Y_test = Y[train:]\n",
    "print(\"testing size: \" + str(len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate classifier object\n",
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# fit the classification model on training set\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# make predictions for testing set\n",
    "pred_rf = classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-One Loss: 0.978823529412\n",
      "Zero-One Score: 0.0211764705882\n",
      "Confusion Matrix:\n",
      "[i, j] is the # of objects truly in group i but predicted to be in group j\n",
      "[[2 2 2 ..., 3 2 0]\n",
      " [3 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " ..., \n",
      " [2 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# compute zero-one loss / score & confusion matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "rf_01 = metrics.zero_one_loss(Y_test, pred_rf) # zero-one loss\n",
    "rf_01_score = metrics.accuracy_score(Y_test, pred_rf) # zero-one score\n",
    "rf_confmat = metrics.confusion_matrix(Y_test, pred_rf) # conf mat\n",
    "\n",
    "print(\"Zero-One Loss: \" + str(rf_01))\n",
    "print(\"Zero-One Score: \" + str(rf_01_score))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"[i, j] is the # of objects truly in group i but predicted to be in group j\")\n",
    "print(rf_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Precision:  0.0186660899654\n",
      "Avg. Recall:  0.0211764705882\n"
     ]
    }
   ],
   "source": [
    "# compute precision and recall\n",
    "# Note: precision & recall are for 2-class; multi-class returns weighted avg. prec/recall\n",
    "\n",
    "rf_precision = metrics.precision_score(Y_test, pred_rf,average=\"weighted\") # TP / (TP + FP)\n",
    "rf_recall = metrics.recall_score(Y_test, pred_rf,average=\"weighted\") # TP / (TP + FN)\n",
    "\n",
    "print(\"Avg. Precision: \",rf_precision)\n",
    "print(\"Avg. Recall: \", rf_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best zero-one score: 0.0793401413983\n",
      "\n",
      "Optimal Model:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "As in class, we fit a random forest with n_estimators = 50\n",
    "Default settings\n",
    "'''\n",
    "\n",
    "# Find the best Random Forest classifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# explore 3 different forest sizes and 3 choices of mtry\n",
    "parameters = {'n_estimators':[20,50,100],  'max_features':[8,10,19], \n",
    "             'criterion': ['gini','entropy']}\n",
    "rf_tune = model_selection.GridSearchCV(RandomForestClassifier(), parameters, \n",
    "                                   n_jobs = -1, cv = 5,verbose=1)\n",
    "rf_opt = rf_tune.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best zero-one score: \" + str(rf_opt.best_score_) + \"\\n\")\n",
    "print(\"Optimal Model:\\n\" + str(rf_opt.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got ~8% accuracy! Not great, but not terrible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06418071,  0.06375888,  0.06170818,  0.06588672,  0.06521994,\n",
       "        0.06528838,  0.06686933,  0.0634906 ,  0.06363924,  0.06334286,\n",
       "        0.07153987,  0.05423789,  0.06162393,  0.06653735,  0.02308432,\n",
       "        0.07959181,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features are corner detection, image array size, and the red color channel variance, respecrively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is our general classifier function that uses X and Y arrays from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We use the arrays 'X' and 'Y' to run our final classifier. \n",
    "Those arrays need to be populated before running this last step\n",
    "'''\n",
    "\n",
    "def general_classifier(X_train, Y_train, path):\n",
    "    # instantiate the classifier using the optimal model determined above and fit the model using our training data\n",
    "    classifier = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features=19, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    # get the validation set of images, extract their features and convert them to arrays\n",
    "    files = []\n",
    "    X_validate = []\n",
    "    image_index = 0\n",
    "    for image_file in os.listdir(path):\n",
    "        X_validate.append(np.zeros(19))\n",
    "        # get image\n",
    "        image = imread(os.path.join(path,image_file)) \n",
    "        # obtain features\n",
    "        feature1, feature2, feature3 = correlation_coeff(image)\n",
    "        feature4, feature5, feature6 = average_color(image)\n",
    "        feature7, feature8, feature9 = color_channel_variance(image)\n",
    "        feature10, feature11 = corner_detection(image)\n",
    "        #feature11 = blob_position_detector(image)\n",
    "        feature12, feature13 = blob_size(image)\n",
    "        feature14 = contours(image)\n",
    "        feature15 = shape_cap_index(image)\n",
    "        feature16 = image_array_size(image)\n",
    "        # add features to X\n",
    "        X[index][0] = feature1\n",
    "        X[index][1] = feature2\n",
    "        X[index][2] = feature3\n",
    "        X[index][3] = feature4\n",
    "        X[index][4] = feature5\n",
    "        X[index][5] = feature6\n",
    "        X[index][6] = feature7\n",
    "        X[index][7] = feature8\n",
    "        X[index][8] = feature9\n",
    "        X[index][9] = feature10\n",
    "        X[index][10] = feature11\n",
    "        X[index][11] = feature12\n",
    "        X[index][12] = feature13\n",
    "        X[index][13] = feature14\n",
    "        X[index][14] = feature15\n",
    "        X[index][15] = feature16\n",
    "        index+=1\n",
    "    files = np.array(files)\n",
    "    X_validate = np.array(X_validate)\n",
    "    # make predictions for validation set\n",
    "    pred_rf = classifier.predict(X_validate) \n",
    "    # add filenames and predictions to a new file\n",
    "    file = open(\"validation.txt\",\"w\") \n",
    "    file.write(\"filename \\t\\t predicted_class \\n\") \n",
    "    file.write(\"---------------------------------------------- \\n\") \n",
    "    for i in range(len(files)):\n",
    "        file.write(files[i]+' \\t\\t '+pred_rf[i]+'\\n')\n",
    "    file.close() \n",
    "    print('file saved as \"validation.txt\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse the following path to run the classifier on your validation set. \\nBe sure to run the entire notebook to get the training data. \\n'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Use the following path to run the classifier on your validation set. \n",
    "Be sure to run the entire notebook to get the training data. \n",
    "'''\n",
    "\n",
    "#path = \"/new/directory/path/\"\n",
    "#run_final_classifier(X,Y,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
