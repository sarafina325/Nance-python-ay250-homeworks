{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_images = 10000\n",
    "n_test = int(n_images/5)\n",
    "n_train = int(n_images)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_width = 45\n",
    "image_height = 45\n",
    "\n",
    "images = np.empty(shape=[0,image_width,image_height])\n",
    "images2 = np.empty(shape=[0,image_width,image_height])\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "\n",
    "filename = os.listdir(os.getcwd()+\"/data_of_lsst/lsst_mocks_single/lensed_outputs/0\")\n",
    "filename2 = os.listdir(os.getcwd()+\"/data_of_lsst/lsst_mocks_single/unlensed_outputs/0\")\n",
    "\n",
    "for file in filename[:n_images]:\n",
    "    if not file.startswith('.'):\n",
    "        try:\n",
    "            image_file = get_pkg_data_filename(\"data_of_lsst/lsst_mocks_single/lensed_outputs/0/\" + file)\n",
    "            image_data = fits.getdata(image_file, ext=0, ignore_missing_end=True, padding=False)\n",
    "            images = np.concatenate((images, [image_data]))\n",
    "        except OSError as err:\n",
    "            print('This file sucks %s' % (image_file))\n",
    "\n",
    "            \n",
    "print (\"Done !\")\n",
    "\n",
    "for file in filename2[:n_images]:\n",
    "    if not file.startswith('.'):\n",
    "        try:\n",
    "            image_file = get_pkg_data_filename(\"data_of_lsst/lsst_mocks_single/unlensed_outputs/0/\" + file)\n",
    "            image_data = fits.getdata(image_file, ext=0, ignore_missing_end=True, padding=False)\n",
    "            images2 = np.concatenate((images2, [image_data]))\n",
    "        except OSError as err:\n",
    "            print('This file sucks %s' % (image_file))\n",
    "\n",
    "print (\"Done !\")\n",
    "\n",
    "lensed_output_0 = images\n",
    "unlensed_output_0 = images2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'nan' from datasets\n",
    "lensed_output_0 = np.where(np.isfinite(lensed_output_0), lensed_output_0, 0)\n",
    "unlensed_output_0 = np.where(np.isfinite(unlensed_output_0), unlensed_output_0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from keras.utils import np_utils\n",
    "\n",
    "# set aside data for testing\n",
    "training_data= np.concatenate((lensed_output_0, unlensed_output_0), axis=0)\n",
    "# testing labels\n",
    "training_labels = np.concatenate((np.ones(n_images), np.zeros(n_images)), axis=0)\n",
    "\n",
    "combined = list(zip(training_data,training_labels))\n",
    "random.shuffle(combined)\n",
    "training_data, training_labels = zip(*combined)\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "X_train = training_data[:int(n_images)*2]\n",
    "y_train = training_labels[:int(n_images)*2]\n",
    "X_test = training_data[16000:n_train]\n",
    "y_test = training_labels[16000:n_train]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "# input data dimensions\n",
    "data_len = 45\n",
    "\n",
    "# reshape X data\n",
    "img_cols = 45\n",
    "img_rows = 45\n",
    "input_shape=(img_cols, img_rows, 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 43, 43, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6402      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,722\n",
      "Trainable params: 6,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 19999 samples, validate on 3999 samples\n",
      "Epoch 1/5\n",
      "19999/19999 [==============================] - 18s 919us/step - loss: 8.0147 - acc: 0.5000 - val_loss: 7.8848 - val_acc: 0.5081\n",
      "Epoch 2/5\n",
      "19999/19999 [==============================] - 18s 887us/step - loss: 8.0147 - acc: 0.5000 - val_loss: 7.8848 - val_acc: 0.5081\n",
      "Epoch 3/5\n",
      "19999/19999 [==============================] - 18s 876us/step - loss: 8.0147 - acc: 0.5000 - val_loss: 7.8848 - val_acc: 0.5081\n",
      "Epoch 4/5\n",
      "19999/19999 [==============================] - 18s 884us/step - loss: 8.0147 - acc: 0.5000 - val_loss: 7.8848 - val_acc: 0.5081\n",
      "Epoch 5/5\n",
      "19999/19999 [==============================] - 18s 895us/step - loss: 8.0147 - acc: 0.5000 - val_loss: 7.8848 - val_acc: 0.5081\n",
      "\n",
      "This CNN has an accuracy of about 51%.\n",
      "Typical accuracies for this training set fall around 50%.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### train and evaluate CNN\n",
    "print('')\n",
    "batch_size=97\n",
    "n_epochs=5\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epochs, \n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "print('')\n",
    "print('This CNN has an accuracy of about' + '% .0f' % (score[1]*100) + '%.')\n",
    "print('Typical accuracies for this training set fall around 50%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.52784616, 1, 1.0),\n",
       " (0.5249349, 1, 1.0),\n",
       " (0.54977274, 1, 1.0),\n",
       " (0.5042342, 1, 1.0),\n",
       " (0.51869714, 1, 0.0),\n",
       " (0.5266753, 1, 0.0),\n",
       " (0.5320569, 1, 0.0),\n",
       " (0.5346558, 1, 0.0),\n",
       " (0.51286584, 1, 1.0),\n",
       " (0.5661322, 1, 0.0),\n",
       " (0.5243514, 1, 1.0),\n",
       " (0.54082507, 1, 1.0),\n",
       " (0.5099284, 1, 0.0),\n",
       " (0.53747445, 1, 1.0),\n",
       " (0.54854506, 1, 1.0),\n",
       " (0.52364546, 1, 1.0),\n",
       " (0.5478093, 1, 1.0),\n",
       " (0.5587346, 1, 0.0),\n",
       " (0.5510385, 1, 0.0),\n",
       " (0.50517875, 1, 1.0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(model.predict(X_test[:20]).T[1], model.predict_classes(X_test[:20]), y_test[0:20]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
