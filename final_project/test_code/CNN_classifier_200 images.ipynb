{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_images = 100\n",
    "n_test = int(n_images/5)\n",
    "n_train = int(n_images)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_width = 45\n",
    "image_height = 45\n",
    "\n",
    "images = np.empty(shape=[0,image_width,image_height])\n",
    "images2 = np.empty(shape=[0,image_width,image_height])\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "\n",
    "filename = os.listdir(os.getcwd()+\"/data_of_lsst/lsst_mocks_single/lensed_outputs/0\")\n",
    "filename2 = os.listdir(os.getcwd()+\"/data_of_lsst/lsst_mocks_single/unlensed_outputs/0\")\n",
    "\n",
    "for file in filename[:n_images]:\n",
    "    if not file.startswith('.'):\n",
    "        try:\n",
    "            image_file = get_pkg_data_filename(\"data_of_lsst/lsst_mocks_single/lensed_outputs/0/\" + file)\n",
    "            image_data = fits.getdata(image_file, ext=0, ignore_missing_end=True, padding=False)\n",
    "            images = np.concatenate((images, [image_data]))\n",
    "        except OSError as err:\n",
    "            print('This file sucks %s' % (image_file))\n",
    "\n",
    "            \n",
    "print (\"Done !\")\n",
    "\n",
    "for file in filename2[:n_images]:\n",
    "    if not file.startswith('.'):\n",
    "        try:\n",
    "            image_file = get_pkg_data_filename(\"data_of_lsst/lsst_mocks_single/unlensed_outputs/0/\" + file)\n",
    "            image_data = fits.getdata(image_file, ext=0, ignore_missing_end=True, padding=False)\n",
    "            images2 = np.concatenate((images2, [image_data]))\n",
    "        except OSError as err:\n",
    "            print('This file sucks %s' % (image_file))\n",
    "\n",
    "print (\"Done !\")\n",
    "\n",
    "lensed_output_0 = images\n",
    "unlensed_output_0 = images2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove 'nan' from datasets\n",
    "lensed_output_0 = np.where(np.isfinite(lensed_output_0), lensed_output_0, 0)\n",
    "unlensed_output_0 = np.where(np.isfinite(unlensed_output_0), unlensed_output_0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarafinanance/anaconda/envs/datascience/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from keras.utils import np_utils\n",
    "\n",
    "# set aside data for testing\n",
    "training_data= np.concatenate((lensed_output_0, unlensed_output_0), axis=0)\n",
    "# testing labels\n",
    "training_labels = np.concatenate((np.ones(n_images), np.zeros(n_images)), axis=0)\n",
    "\n",
    "combined = list(zip(training_data,training_labels))\n",
    "random.shuffle(combined)\n",
    "training_data, training_labels = zip(*combined)\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "X_train = training_data[:int(n_images)*2]\n",
    "y_train = training_labels[:int(n_images)*2]\n",
    "X_test = training_data[16000:n_train]\n",
    "y_test = training_labels[16000:n_train]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "# input data dimensions\n",
    "data_len = 45\n",
    "\n",
    "# reshape X data\n",
    "img_cols = 45\n",
    "img_rows = 45\n",
    "input_shape=(img_cols, img_rows, 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 43, 43, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6402      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,722\n",
      "Trainable params: 6,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 200 samples, validate on 0 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.8099 - acc: 0.4950\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.0151 - acc: 0.5000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.0151 - acc: 0.5000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 912us/step - loss: 8.0151 - acc: 0.5000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 963us/step - loss: 8.0151 - acc: 0.5000\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ffd0db35f217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This CNN has an accuracy of about'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'% .0f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Typical accuracies for this training set fall around 50%.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### train and evaluate CNN\n",
    "print('')\n",
    "batch_size=97\n",
    "n_epochs=5\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epochs, \n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "print('')\n",
    "print('This CNN has an accuracy of about' + '% .0f' % (score[1]*100) + '%.')\n",
    "print('Typical accuracies for this training set fall around 50%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.52784616, 1, 1.0),\n",
       " (0.5249349, 1, 1.0),\n",
       " (0.54977274, 1, 1.0),\n",
       " (0.5042342, 1, 1.0),\n",
       " (0.51869714, 1, 0.0),\n",
       " (0.5266753, 1, 0.0),\n",
       " (0.5320569, 1, 0.0),\n",
       " (0.5346558, 1, 0.0),\n",
       " (0.51286584, 1, 1.0),\n",
       " (0.5661322, 1, 0.0),\n",
       " (0.5243514, 1, 1.0),\n",
       " (0.54082507, 1, 1.0),\n",
       " (0.5099284, 1, 0.0),\n",
       " (0.53747445, 1, 1.0),\n",
       " (0.54854506, 1, 1.0),\n",
       " (0.52364546, 1, 1.0),\n",
       " (0.5478093, 1, 1.0),\n",
       " (0.5587346, 1, 0.0),\n",
       " (0.5510385, 1, 0.0),\n",
       " (0.50517875, 1, 1.0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(model.predict(X_test[:20]).T[1], model.predict_classes(X_test[:20]), y_test[0:20]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
